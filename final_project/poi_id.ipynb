{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Fraud From Enron Email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nanodegree project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "from pprint import pprint\n",
    "import ggplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Load the dictionary containing the dataset\n",
    "data_dict = pickle.load(open(\"final_project_dataset.pkl\", \"r\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One - Understanding the Dataset and Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "To better understand the dataset, an exploration is performed here and the results are summarized as following,\n",
    "- there are 146 data points with 21 features.\n",
    "- there are 18 people who is an point of interest.\n",
    "- 1,358 data points are missing.\n",
    "- the top 3 features with most missing values are \"loan_advances\", \"director_fees\", and \"restricted_stock_deferred\".\n",
    "\n",
    "More detailed exploration and analysis are listed as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of data points\n",
    "len(data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of features available\n",
    "len(data_dict['METTS MARK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['salary',\n",
       " 'to_messages',\n",
       " 'deferral_payments',\n",
       " 'total_payments',\n",
       " 'exercised_stock_options',\n",
       " 'bonus',\n",
       " 'restricted_stock',\n",
       " 'shared_receipt_with_poi',\n",
       " 'restricted_stock_deferred',\n",
       " 'total_stock_value',\n",
       " 'expenses',\n",
       " 'loan_advances',\n",
       " 'from_messages',\n",
       " 'other',\n",
       " 'from_this_person_to_poi',\n",
       " 'poi',\n",
       " 'director_fees',\n",
       " 'deferred_income',\n",
       " 'long_term_incentive',\n",
       " 'email_address',\n",
       " 'from_poi_to_this_person']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# available features\n",
    "data_dict[\"METTS MARK\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HANNON KEVIN P\n",
      "COLWELL WESLEY\n",
      "RIEKER PAULA H\n",
      "KOPPER MICHAEL J\n",
      "SHELBY REX\n",
      "DELAINEY DAVID W\n",
      "LAY KENNETH L\n",
      "BOWEN JR RAYMOND M\n",
      "BELDEN TIMOTHY N\n",
      "FASTOW ANDREW S\n",
      "CALGER CHRISTOPHER F\n",
      "RICE KENNETH D\n",
      "SKILLING JEFFREY K\n",
      "YEAGER F SCOTT\n",
      "HIRKO JOSEPH\n",
      "KOENIG MARK E\n",
      "CAUSEY RICHARD A\n",
      "GLISAN JR BEN F\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# people of interest\n",
    "count = 0\n",
    "for item, value in data_dict.iteritems():\n",
    "    if value[\"poi\"]:\n",
    "        print item\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a dictionary for all missing values\n",
    "missing = {}\n",
    "for item, value in data_dict.iteritems():\n",
    "    for key, figure in value.iteritems():\n",
    "        if figure == \"NaN\":\n",
    "            if key not in missing:\n",
    "                missing[key] = 1\n",
    "            else:\n",
    "                missing[key] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1358"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of missing values\n",
    "number_of_missing = 0\n",
    "for item, value in missing.iteritems():\n",
    "    number_of_missing += value\n",
    "number_of_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 64,\n",
       " 'deferral_payments': 107,\n",
       " 'deferred_income': 97,\n",
       " 'director_fees': 129,\n",
       " 'email_address': 35,\n",
       " 'exercised_stock_options': 44,\n",
       " 'expenses': 51,\n",
       " 'from_messages': 60,\n",
       " 'from_poi_to_this_person': 60,\n",
       " 'from_this_person_to_poi': 60,\n",
       " 'loan_advances': 142,\n",
       " 'long_term_incentive': 80,\n",
       " 'other': 53,\n",
       " 'restricted_stock': 36,\n",
       " 'restricted_stock_deferred': 128,\n",
       " 'salary': 51,\n",
       " 'shared_receipt_with_poi': 60,\n",
       " 'to_messages': 60,\n",
       " 'total_payments': 21,\n",
       " 'total_stock_value': 20}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:  LAY KENNETH L poi: True\n",
      "name:  PICKERING MARK R poi: False\n",
      "name:  TOTAL poi: False\n",
      "name:  FREVERT MARK A poi: False\n"
     ]
    }
   ],
   "source": [
    "# check who isn't missing the feature 'load_advances'\n",
    "# outputs the person's name and a boolean value indicated whether the person is a poi.\n",
    "for item, value in data_dict.iteritems():\n",
    "    if value[\"loan_advances\"] != \"NaN\":\n",
    "        print \"name: \", item, \"poi:\", value[\"poi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name CHAN RONNIE poi: False\n",
      "name BELFER ROBERT poi: False\n",
      "name URQUHART JOHN A poi: False\n",
      "name MENDELSOHN JOHN poi: False\n",
      "name WAKEHAM JOHN poi: False\n",
      "name POWERS WILLIAM poi: False\n",
      "name DUNCAN JOHN H poi: False\n",
      "name LEMAISTRE CHARLES poi: False\n",
      "name MEYER JEROME J poi: False\n",
      "name PEREIRA PAULO V. FERRAZ poi: False\n",
      "name BLAKE JR. NORMAN P poi: False\n",
      "name TOTAL poi: False\n",
      "name JAEDICKE ROBERT poi: False\n",
      "name WINOKUR JR. HERBERT S poi: False\n",
      "name BHATNAGAR SANJAY poi: False\n",
      "name SAVAGE FRANK poi: False\n",
      "name GRAMM WENDY L poi: False\n"
     ]
    }
   ],
   "source": [
    "# check who isn't missing the feature 'director_fees'\n",
    "# outputs the person's name and a boolean value indicated whether the person is a poi.\n",
    "for item, value in data_dict.iteritems():\n",
    "    if value[\"director_fees\"] != \"NaN\":\n",
    "        print \"name\", item, \"poi:\", value[\"poi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name PIPER GREGORY F poi: False\n",
      "name LOWRY CHARLES P poi: False\n",
      "name CHAN RONNIE poi: False\n",
      "name BELFER ROBERT poi: False\n",
      "name CLINE KENNETH W poi: False\n",
      "name DETMERING TIMOTHY J poi: False\n",
      "name BANNANTINE JAMES M poi: False\n",
      "name GATHMANN WILLIAM D poi: False\n",
      "name HAEDICKE MARK E poi: False\n",
      "name NOLES JAMES L poi: False\n",
      "name TOTAL poi: False\n",
      "name ALLEN PHILLIP K poi: False\n",
      "name JAEDICKE ROBERT poi: False\n",
      "name REYNOLDS LAWRENCE poi: False\n",
      "name BHATNAGAR SANJAY poi: False\n",
      "name CARTER REBECCA C poi: False\n",
      "name DERRICK JR. JAMES V poi: False\n",
      "name BAY FRANKLIN R poi: False\n"
     ]
    }
   ],
   "source": [
    "# check who isn't missing the feature 'restricted_stock_deferred'\n",
    "# outputs the person's name and a boolean value indicated whether the person is a poi.\n",
    "for item, value in data_dict.iteritems():\n",
    "    if value[\"restricted_stock_deferred\"] != \"NaN\":\n",
    "        print \"name\", item, \"poi:\", value[\"poi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name BAXTER JOHN C poi: False\n",
      "name MEYER ROCKFORD G poi: False\n",
      "name HORTON STANLEY C poi: False\n",
      "name PIPER GREGORY F poi: False\n",
      "name HUMPHREY GENE E poi: False\n",
      "name GIBBS DANA R poi: False\n",
      "name COLWELL WESLEY poi: True\n",
      "name MULLER MARK S poi: False\n",
      "name WALTERS GARETH W poi: False\n",
      "name BELFER ROBERT poi: False\n",
      "name RIEKER PAULA H poi: True\n",
      "name HAYES ROBERT E poi: False\n",
      "name DETMERING TIMOTHY J poi: False\n",
      "name SULLIVAN-SHAKLOVITZ COLLEEN poi: False\n",
      "name LINDHOLM TOD A poi: False\n",
      "name LAY KENNETH L poi: True\n",
      "name OLSON CINDY K poi: False\n",
      "name GAHN ROBERT S poi: False\n",
      "name HAEDICKE MARK E poi: False\n",
      "name BAZELIDES PHILIP J poi: False\n",
      "name BELDEN TIMOTHY N poi: True\n",
      "name THORN TERENCE H poi: False\n",
      "name FOY JOE poi: False\n",
      "name PRENTICE JAMES poi: False\n",
      "name GRAY RODNEY poi: False\n",
      "name NOLES JAMES L poi: False\n",
      "name TOTAL poi: False\n",
      "name WASAFF GEORGE poi: False\n",
      "name ALLEN PHILLIP K poi: False\n",
      "name SHARP VICTORIA T poi: False\n",
      "name BADUM JAMES P poi: False\n",
      "name REYNOLDS LAWRENCE poi: False\n",
      "name HIRKO JOSEPH poi: True\n",
      "name FREVERT MARK A poi: False\n",
      "name BAY FRANKLIN R poi: False\n",
      "name FUGH JOHN L poi: False\n",
      "name MARTIN AMANDA K poi: False\n",
      "name BUY RICHARD B poi: False\n",
      "name TAYLOR MITCHELL S poi: False\n"
     ]
    }
   ],
   "source": [
    "# check who isn't missing the feature 'deferral_payments'\n",
    "# outputs the person's name and a boolean value indicated whether the person is a poi.\n",
    "for item, value in data_dict.iteritems():\n",
    "    if value[\"deferral_payments\"] != \"NaN\":\n",
    "        print \"name\", item, \"poi:\", value[\"poi\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, it doesn't seem to have a clear pattern on whether a poi is missing a value or not. The investigation on missing values ends here, and the missing values will be replaced with '0' after feature formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Select Features\n",
    "As a starting point, all the available features will be selected and put into the model. Later in this report, some features will be removed based on their PCA importance score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = ['poi',\n",
    "                 'salary',\n",
    "                 'to_messages',\n",
    "                 'deferral_payments',\n",
    "                 'total_payments',\n",
    "                 'exercised_stock_options',\n",
    "                 'bonus',\n",
    "                 'restricted_stock',\n",
    "                 'shared_receipt_with_poi',\n",
    "                 'restricted_stock_deferred',\n",
    "                 'total_stock_value',\n",
    "                 'expenses',\n",
    "                 'loan_advances',\n",
    "                 'from_messages',\n",
    "                 'other',\n",
    "                 'from_this_person_to_poi',\n",
    "                 'poi',\n",
    "                 'director_fees',\n",
    "                 'deferred_income',\n",
    "                 'long_term_incentive',\n",
    "                 'from_poi_to_this_person']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def outlierCleaner(predictions, ages, net_worths):\n",
    "    \"\"\"\n",
    "        clean away the 10% of points that have the largest\n",
    "        residual errors (different between the prediction\n",
    "        and the actual net worth)\n",
    "\n",
    "        return a list of tuples named cleaned_data where\n",
    "        each tuple is of the form (age, net_worth, error)\n",
    "    \"\"\"\n",
    "\n",
    "    cleaned_data = []\n",
    "\n",
    "    length = int(len(predictions) * 0.9)\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        result = ages[i], net_worths[i], (net_worths[i] - predictions[i]) ** 2\n",
    "        cleaned_data.append(tuple(result))\n",
    "\n",
    "    cleaned_data.sort(key=lambda value: value[2])\n",
    "\n",
    "    cleaned_data = cleaned_data[: length]\n",
    "    print len(cleaned_data)\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.covariance import EllipticEnvelope\n",
    "outlier_cleaner = EllipticEnvelope(contamination = 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two - Optimize Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Three - Pick and Tune an Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Four - Validate and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Create new feature(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import linear_model, datasets\n",
    "\n",
    "\n",
    "n_samples = 1000\n",
    "n_outliers = 50\n",
    "\n",
    "\n",
    "X, y, coef = datasets.make_regression(n_samples=n_samples, n_features=1,\n",
    "                                      n_informative=1, noise=10,\n",
    "                                      coef=True, random_state=0)\n",
    "\n",
    "# Add outlier data\n",
    "np.random.seed(0)\n",
    "X[:n_outliers] = 3 + 0.5 * np.random.normal(size=(n_outliers, 1))\n",
    "y[:n_outliers] = -3 + 10 * np.random.normal(size=n_outliers)\n",
    "\n",
    "# Fit line using all data\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Robustly fit linear model with RANSAC algorithm\n",
    "model_ransac = linear_model.RANSACRegressor(linear_model.LinearRegression())\n",
    "model_ransac.fit(X, y)\n",
    "inlier_mask = model_ransac.inlier_mask_\n",
    "outlier_mask = np.logical_not(inlier_mask)\n",
    "\n",
    "# Predict data of estimated models\n",
    "line_X = np.arange(-5, 5)\n",
    "line_y = model.predict(line_X[:, np.newaxis])\n",
    "line_y_ransac = model_ransac.predict(line_X[:, np.newaxis])\n",
    "\n",
    "# Compare estimated coefficients\n",
    "print(\"Estimated coefficients (true, normal, RANSAC):\")\n",
    "print(coef, model.coef_, model_ransac.estimator_.coef_)\n",
    "\n",
    "plt.plot(X[inlier_mask], y[inlier_mask], '.g', label='Inliers')\n",
    "plt.plot(X[outlier_mask], y[outlier_mask], '.r', label='Outliers')\n",
    "plt.plot(line_X, line_y, '-k', label='Linear regressor')\n",
    "plt.plot(line_X, line_y_ransac, '-b', label='RANSAC regressor')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Try a varity of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Provided to give you a starting point. Try a variety of classifiers.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Tune your classifier to achieve better than .3 precision and recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Dump your classifier, dataset, and features_list so anyone can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
