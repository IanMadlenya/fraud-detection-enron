{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Fraud from Enron Email\n",
    "\n",
    "## Yong Yu\n",
    "\n",
    "This is a report on the process of builing estimators for Fraud Detection using machine learning.\n",
    "\n",
    "A more compact and summurized report can be found as \n",
    "<a href='https://raw.githubusercontent.com/yyforyongyu/nanodegree-machine-learning/master/final_project/documentation.html' target='_blank'>Documentation (html)</a>, or \n",
    "<a href='https://github.com/yyforyongyu/nanodegree-machine-learning/blob/master/final_project/documentation.ipynb' target='_blank'> Documentation (ipynb) </a>.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this report, there are series of investigations performed to make a robust, strong final estimator to predict a person-of-interest(poi). These include,\n",
    "- an overview of the dataset.\n",
    "- outlier cleaning.\n",
    "- a performance comparison among different feature scaling methods, including MinMaxScaler, StandardScaler, and Normalizer.\n",
    "- creating three features, \"stock_salary_ratio\", \"poi_from_ratio\", \"poi_to_ratio\", and evaluating them.\n",
    "- a performance comparison between two different feature selection methods, SelectKBest and ExtraTreesClassifier.\n",
    "- a performance comparison between including PCA and excluding PCA.\n",
    "- a performance comparison between different classifiers, LinearSVC and KNeighborsClassifier.\n",
    "- tuning algorithms using F1 score as evaluation metric.\n",
    "- cross-validation on the final estimator.\n",
    "\n",
    "Several helper functions are built for this project in poi_helper.py. Since this report only focuses on methodology in machine learning, we will not cover them here. For more details, report \n",
    "<a href='https://github.com/yyforyongyu/nanodegree-machine-learning/blob/master/final_project/poi_id.ipynb' target='_blank'>poi_id.ipynb</a>\n",
    "has all the thoughts and steps in building these functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "When finding a best combination out of groups of factors, there are usually two ways to think about it. One way would be simply find the best solution from each group, then chain all the solutions together to make the final combination. The assumption is that the best of each independent thing can be grouped to be the best of a new thing. In reality, this is rarely true since the best from one group might have a negtive effect on the best from another group. If we are to apply this method into the analysis, in short, we would need to first, find the best feature selection method, then find the best calssifier, lastly combine the feature selection and classifier to make the final estimator. However, from the report \n",
    "<a href='https://github.com/yyforyongyu/nanodegree-machine-learning/blob/master/final_project/poi_id.ipynb' target='_blank'>poi_id.ipynb</a>,\n",
    "using a SelectKBest + LinearSVC could have an accuracy score of 0.94, same when using RandomizedLogisticRegression + KNeighbors, although the runtimes were different. However, when applying RandomizedLogisticRegression + LinearSVC, or SelectKBest + KNeighbors, accuracy scores became lower. This clearly indicates that, for each classifier algorithm, there is a best fit feature selection method. Simply chaining a best classifier and a feature selection seperately won't produce the best result. It becomes rather clear when all the algorithms were applied on both outlier-cleaned and full datasets. The best estimator for one dataset won't work on a different dataset.\n",
    "\n",
    "So machine learning is really about finding a specific, nearly unique solution to a question, which brings me to think about the second way, exhaustively trying out combinations of all factors, rather than finding a best answer by groups. This assumes that a simple change in one unit can make a total difference. Unfortunately, this method also creates a problem, large time consumptions.\n",
    "\n",
    "For this analysis, the dataset will be tested with or without PCA, with four feature scaling methods(including not using one), with two feature selection methods, and two classifiers, considering only 20 values to be tuned on each classifier, 20 values to be tuned on each feature selection, and 10 values to be tuned on PCA, a rough total number of combinations is,\n",
    "$$ 2*4*2*2*20*20*10 = 128,000$$\n",
    "And it is not likely we will conduct all the possibilies here at once, we will have to make a tradeoff.\n",
    "\n",
    "For this analysis, the parameters of feature selection methods won't be tuned untill one best feature selection method is found, then the cross validation will be tuned, which brings the possible combination down dramstically before we start to tune on feature selection and cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Dataset\n",
    "A summary of findings,\n",
    "- there are 146 data points with 21 features, and a total of 3066 obervations.\n",
    "- there are 18 people who is an point of interest.\n",
    "- 1,358 data points are missing.\n",
    "- the top 3 features with most missing values are \"loan_advances\", \"director_fees\", and \"restricted_stock_deferred\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "from tester import dump_classifier_and_data, test_classifier\n",
    "sys.path.append(\"../tools/\")\n",
    "from poi_helper import *\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "data_dict = pickle.load(open(\"final_project_dataset.pkl\", \"r\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of data points\n",
    "len(data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of features available\n",
    "len(data_dict['METTS MARK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# available features\n",
    "data_dict[\"METTS MARK\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# people of interest\n",
    "count = 0\n",
    "for key, item in data_dict.iteritems():\n",
    "    if item[\"poi\"]:\n",
    "        print key\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dictionary for all missing values\n",
    "missing = {}\n",
    "for key, item in data_dict.iteritems():\n",
    "    for elem, value in item.iteritems():\n",
    "        if value == \"NaN\":\n",
    "            if elem not in missing:\n",
    "                missing[elem] = 1\n",
    "            else:\n",
    "                missing[elem] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of missing values\n",
    "number_of_missing = 0\n",
    "for key, item in missing.iteritems():\n",
    "    number_of_missing += item\n",
    "number_of_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we already known in mini projects, there is an outlier named \"TOTAL\" in this dataset. We will need to remove it before any further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove the outlier 'TOTAL'\n",
    "data_dict.pop(\"TOTAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots of the Outliers\n",
    "\n",
    "To understand the outliers in this dataset, plots are created by using salary against every other feature but poi, which is used to color data points in each plot. As a starting point, all the available features will be selected and put into the model. Later in this report, some features will be removed based on their feature selection score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create features for plots\n",
    "# features_list is a list of strings, each of which is a feature name.\n",
    "# The first feature must be \"poi\".\n",
    "features_list = ['poi',\n",
    "                 'salary',\n",
    "                 'to_messages',\n",
    "                 'deferral_payments',\n",
    "                 'total_payments',\n",
    "                 'exercised_stock_options',\n",
    "                 'bonus',\n",
    "                 'restricted_stock',\n",
    "                 'shared_receipt_with_poi',\n",
    "                 'restricted_stock_deferred',\n",
    "                 'total_stock_value',\n",
    "                 'expenses',\n",
    "                 'loan_advances',\n",
    "                 'from_messages',\n",
    "                 'other',\n",
    "                 'from_this_person_to_poi',\n",
    "                 'director_fees',\n",
    "                 'deferred_income',\n",
    "                 'long_term_incentive',\n",
    "                 'from_poi_to_this_person']\n",
    "\n",
    "# format the dataset\n",
    "data = featureFormat(data_dict, features_list)\n",
    "\n",
    "# create a pandas dataframe\n",
    "df = pd.DataFrame(data, columns = features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following plots, blue color stands for poi, red color stands for non-poi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ggplot import *\n",
    "\n",
    "# iter through all features\n",
    "# x axis will always be salary\n",
    "# poi is represented by colors of points\n",
    "# the rest of features are put in y axis\n",
    "for feature in features_list:\n",
    "    if feature != \"poi\" and feature != \"salary\":\n",
    "        print ggplot(aes(x = 'salary', y = feature, color = 'poi'),\n",
    "               data = df) +\\\n",
    "        geom_point() +\\\n",
    "        ggtitle(\"salary against \" + feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Removal\n",
    "\n",
    "The purpose of removing outliers is to prevent the model being misrepresented by extreme cases, which comes with an assumption that either the extreme cases rarely happen, or they don't carry engough valuable infomration to be kept in the model. This can be true for some of the features, but could be controversy for \"total_payment\" feature, and shouldn't be applied to \"exercised_stock_options\" as the top four outliers are all person of interest. On the other hand, if we are to treat top 10% of each feature as outliers, it is not hard to imagine that the final dataset will have much less than 90%. A large deduction in the original dataset will cause the model becoming weaker.\n",
    "\n",
    "Given all these thoughts, we will start the cleaning experiment using a simple method. By fitting in a linear regression model, we will calculate the variance between the predicted values and true values, then treat features whoes predictions have top 10% variance as outliers. Based on that, we can then decide what to do with the outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### check on the score before outlier cleaning\n",
    "features, labels = featureLabelSplit(data_dict, features_list)\n",
    "buildRegression(features, labels)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### clean the outliers\n",
    "### extract normal data points and outliers\n",
    "cleaned_data, outliers = outlierCleaner(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### extract labels and features from cleaned_data\n",
    "cleaned_labels, cleaned_features = targetFeatureSplit(cleaned_data)\n",
    "\n",
    "# fit the model again and check the score\n",
    "buildRegression(cleaned_features, cleaned_labels)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A removal of the outliers improved the score of the linear model dramastically from 0.35 to 0.82. Although it's good to see improvement in score, it's always necessary to take a look at the removed outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### change the data format from numpy array to python dictionary\n",
    "outliers_dataset = personMapping(featureReformat(outliers, features_list), data_dict, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### number of outliers\n",
    "len(outliers_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### name of outliers who is not a poi\n",
    "for key, item in outliers_dataset.iteritems():\n",
    "    if item['poi'] == 0.0:\n",
    "        print key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy on Outlier Removal\n",
    "\n",
    "As mentioned above, simply removing the outliers might cause an issue for later on analysis. While the imporvement in score of the linear model is surely tempting, do note that, this is not the model that we will use to conduct machine learning in this dataset. \n",
    "\n",
    "On the other hand, there's no surprising that most of the person of interest(13 out 18) are flagged as outliers given the background knowledge of Enron Fraud. In this case, the outliers are the targets we want to find, according to <a href='https://discussions.udacity.com/t/outlier-removal/7446' target='_blank'>this post in discussion forum</a>, we can manually decided to include or exclude the outliers or not in the training set. This strategy will be applied when processing the dataset.\n",
    "\n",
    "Given the though above, when fitting in datasets later, there are 5% outliers cleaned on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preprocessing Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Creation\n",
    "To dig out more patterns from the dataset, three new features, \"stock_salary_ratio\", \"poi_from_ratio\", \"poi_to_ratio\", are created as following.\n",
    "\n",
    "- stock_salary_ratio: stock_salary_ratio takes the result from total_stock_value divided by salary. This feature is useful based on the assumption that a person of interest usually has a unusual large stock value since it's under the table, while salary information could be more easily known by public, thus the ratio could give information to identify the poi. The bigger the ratio, the more likely it is a poi.\n",
    "- poi_from_ratio: poi_from_ratio takes result from from_poi_to_this_person divided by from_messages. This feature assumes that if a person is a poi, he/she tends to have more contacts with another poi, therefore the ratio would be bigger. And same applie to feature poi_to_ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### add new features to dataset\n",
    "for key, item in data_dict.iteritems():\n",
    "    ### add stock_salary_ratio\n",
    "    if item['salary'] != \"NaN\" and item['total_stock_value'] != \"NaN\":\n",
    "        item['stock_salary_ratio'] = float(item['total_stock_value']) / item['salary']\n",
    "    else:\n",
    "        item['stock_salary_ratio'] = \"NaN\"\n",
    "    \n",
    "    ### add poi_from_ratio\n",
    "    if item['from_messages'] != \"NaN\" and item['from_poi_to_this_person'] != \"NaN\":\n",
    "        item['poi_from_ratio'] = float(item['from_poi_to_this_person']) / item['from_messages']\n",
    "    else:\n",
    "        item['poi_from_ratio'] = \"NaN\"\n",
    "        \n",
    "    ### add poi_to_ratio\n",
    "    if item[\"to_messages\"] != \"NaN\" and item[\"from_this_person_to_poi\"] != \"NaN\":\n",
    "        item[\"poi_to_ratio\"] = float(item[\"from_this_person_to_poi\"]) / item[\"to_messages\"]\n",
    "    else:\n",
    "        item[\"poi_to_ratio\"] = \"NaN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### update features list\n",
    "new_features_list = features_list + [\"stock_salary_ratio\", \"poi_from_ratio\", \"poi_to_ratio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Depending on the algorithms chosen, feature scaling may be necessary. In this report, three feature scaling methods are compared, including MinMaxScaler, StandardScaler, and Normalizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stdMeanReader(features, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### check results from MinMaxScaler\n",
    "stdMeanReader(features, features_list, MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### check results from StandardScaler\n",
    "stdMeanReader(features, features_list, StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### check results from Normalizer\n",
    "stdMeanReader(features, features_list, Normalizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### create scalers\n",
    "scalers = [('none', None),\n",
    "           ('standardscaler', StandardScaler()),\n",
    "           ('minmaxscaler', MinMaxScaler()),\n",
    "           ('normalier', Normalizer())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "To get a better processing before any fitting into models, two feature selection methods for classification listed in \n",
    "<a href='http://scikit-learn.org/stable/modules/feature_selection.html' target='_blank'>sklearn documentations</a> \n",
    "are explored, which are SelectKBest and ExtraTreesClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "feature_selections = [('k_best', SelectKBest(k = 'all')),\n",
    "                     ('extra_tree', ExtraTreesClassifier(class_weight='auto', random_state=42))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "PCA is imported to conduct dimensions deduction. Depending on the performances, the decision to include PCA or not will be made later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = [('none', None),\n",
    "       ('pca', PCA())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick and Prepare Classifiers\n",
    "\n",
    "According to \n",
    "<a href='http://scikit-learn.org/stable/tutorial/machine_learning_map/' target='_blank'>this cheat sheet in sklearn</a>, \n",
    "there are at least four classification methods can be used,\n",
    "- LinearSVC\n",
    "- KNeighbors Classifier\n",
    "- SVC\n",
    "- Ensemble Classifers\n",
    "\n",
    "In this report, we will check on LinearSVC and KNeighborsClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "linear_svc = LinearSVC(class_weight='auto', penalty='l1', dual=False, random_state=42)\n",
    "\n",
    "params_svc = {'linear_svc__C':[0.01, 0.03, 0.1, 0.3, 1, 3, 10],\n",
    "              'linear_svc__tol': [1e-4, 1e-3, 1e-2, 1],\n",
    "              'linear_svc__max_iter': [1e3, 1e4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k_neighbors = KNeighborsClassifier(weights='distance', algorithm='auto')\n",
    "\n",
    "params_kneighbors = {'k_neighbors__n_neighbors': [1, 3, 10],\n",
    "                     'k_neighbors__leaf_size': [2, 5, 10, 30, 50, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### put all classifiers together\n",
    "classifiers = [('linear_svc', linear_svc, params_svc),\n",
    "               ('k_neighbors', k_neighbors, params_kneighbors)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation and Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "To prevent overfitting, a cross validation is needed to split the dataset into training and testing. StratifiedShuffleSplit is used across all tuning processes with a default test_size of 0.1. Depending on different steps, the n_iter paramter used for cross validation varies, as listed below,\n",
    "\n",
    "- when finding best combination of feature selection and classification method, n_iter = 100;\n",
    "- when tuning on the chosen estimator, n_iter = 1000;\n",
    "- when tuning on the chosen feature selection, n_iter = 100.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "For evaluation, we will use accuracy score, f1 score, precision score, recall score and time consumption when deciding the best estimator. When performing grid search, f1 score is used as a scoring parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When runing the esimators on the dataset, there are 8 models generated seperately for scaled and non-scaled features. A comparison among the best choices is as following, listed as model number, feature selection method, classification method, accuracy score, F1 score, precision score, recall score, and time consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### create pipelines\n",
    "pipelines = makePipelines(scalers, pca, feature_selections, classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### train models on features list\n",
    "model_sets, scores = trainModel(data_dict, features_list, pipelines,\n",
    "                                filename = 'model_metrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### train models on new features list\n",
    "model_sets_new, scores_new = trainModel(data_dict, new_features_list, pipelines,\n",
    "                                        filename = 'model_metrix_new_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"model_metrix.csv\").sort(['f1_score','time_used'], ascending= [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"model_metrix_new_features.csv\").sort(['f1_score','time_used'], ascending= [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Final Tuning on the Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Information for Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### extract the pipeline\n",
    "pipeline = model_sets[22][1]\n",
    "tuning_score = scores[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### get the training and testing set\n",
    "features_train, features_test, labels_train, labels_test = trainTestSplit(data_dict, features_list)\n",
    "\n",
    "### prepare the cross validation\n",
    "sss = StratifiedShuffleSplit(labels_train, n_iter=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### check on grid score\n",
    "gridScoreReader(tuning_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### extract algorithms\n",
    "pca = pipeline.steps[1][1].transformer_list[0][1]\n",
    "extra_tree = pipeline.steps[1][1].transformer_list[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### check feature importances on features list\n",
    "extra_tree_result = zip(features_list[1:], extra_tree.feature_importances_)\n",
    "extra_tree_result.sort(key=lambda value:value[1], reverse=True)\n",
    "\n",
    "### check feature importances\n",
    "extra_tree_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### check feature importances on  new features list\n",
    "### extract extra tree\n",
    "new_extra_tree = model_sets_new[22][1].steps[1][1].transformer_list[1][1]\n",
    "\n",
    "### get all the features\n",
    "new_extra_tree_result = zip(new_features_list[1:], new_extra_tree.feature_importances_)\n",
    "new_extra_tree_result.sort(key=lambda value:value[1], reverse=True)\n",
    "\n",
    "### check feature importances\n",
    "new_extra_tree_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### check pca explained variance ratio on features list\n",
    "pca = pipeline.steps[1][1].transformer_list[0][1]\n",
    "pca.explained_variance_ratio_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### check pca explained variance ratio on new features list\n",
    "pca_new = model_sets_new[22][1].steps[1][1].transformer_list[0][1]\n",
    "pca_new.explained_variance_ratio_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning on ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### record time\n",
    "t0 = time()\n",
    "\n",
    "### set the parameters\n",
    "params_extra_tree = {\"extra_tree_with_pca__extra_tree__n_estimators\": [1, 3, 10, 30, 100],\n",
    "                     \"extra_tree_with_pca__extra_tree__max_features\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "\n",
    "### fit and search\n",
    "estimator = GridSearchCV(pipeline, params_extra_tree, scoring='f1', cv=sss)\n",
    "estimator.fit(features_train, labels_train)\n",
    "\n",
    "### extract scores\n",
    "score_extra_tree = estimator.grid_scores_\n",
    "\n",
    "### get the best estimator\n",
    "clf = estimator.best_estimator_\n",
    "\n",
    "### check the model performance\n",
    "crossValidate(data_dict, features_list, clf)\n",
    "\n",
    "print \"time used: \", time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### extract algorithm\n",
    "extra_tree = clf.steps[1][1].transformer_list[1][1]\n",
    "\n",
    "### get the score\n",
    "extra_tree_result = zip(features_list[1:], extra_tree.feature_importances_)\n",
    "extra_tree_result.sort(key=lambda value:value[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### check feature importances\n",
    "extra_tree_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gridScoreReader(score_extra_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning on PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### record time\n",
    "t0 = time()\n",
    "\n",
    "### set the parameters\n",
    "params_pca = {\"extra_tree_with_pca__pca__n_components\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "              \"extra_tree_with_pca__pca__whiten\": [True, False]}\n",
    "\n",
    "### fit and search\n",
    "estimator = GridSearchCV(clf, params_pca, scoring='f1', cv=sss)\n",
    "estimator.fit(features_train, labels_train)\n",
    "\n",
    "### extract scores\n",
    "score_pca = estimator.grid_scores_\n",
    "\n",
    "### get the best estimator\n",
    "clf = estimator.best_estimator_\n",
    "\n",
    "### check the model performance\n",
    "crossValidate(data_dict, features_list, clf)\n",
    "\n",
    "print \"time used: \", time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### check on explained ratio\n",
    "clf.steps[1][1].transformer_list[0][1].explained_variance_ratio_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gridScoreReader(score_pca).sort([\"whiten\", \"n_components\"], ascending = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Final Solution\n",
    "\n",
    "After comparing among feature selection methods, classification methods, carefully tuning parameters for the methods, the best model turned out to be a combination of the following,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### check on the parameters\n",
    "clf.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### prepare for the test\n",
    "clf = clf\n",
    "my_dataset = data_dict\n",
    "features_list = features_list\n",
    "\n",
    "### dump for testing\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### check the score from tester\n",
    "test_classifier(clf, my_dataset, features_list, folds = 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
